= Creating Document Actions 

include::partial$document-action.adoc[tag=definition] 

Create a document action using a predefined type as a template, and then specify which fields are mandatory, which fields to exclude from the JSON response, and the minimum confidence score expected for each field. 

You can also extract specific data from a document using questions in natural language, for example:

* What is the subtotal amount?
* What is the grand total?
* When is the due date?
* What is the highest price?

After you create a new document action, you can add reviewers and publish it to Anypoint Exchange, which enables RPA to execute the document action and also creates an API that you can call from any external system. 

When you create a document action, ensure that the configured schema works for each uploaded document. If you can't customize the schema to work with all sample documents, consider creating multiple document actions. For example, purchase orders from multiple vendors might be different enough to require a separate document action for each vendor.

Creating a document action requires the following tasks:

. <<upload-files>>
. <<configure-schema>>
. <<add-prompts>>

== Before You Begin 

Ensure you have any of the following Anypoint permissions:

include::partial$permissions.adoc[tag=permissionManage]

include::partial$permissions.adoc[tag=permissionBuild]

[[upload-files]]
== Upload Sample Files and Preview the Results

To start creating a new document action, upload sample files to test the extraction process: 

//starting steps
include::partial$create-document-actions.adoc[tag=initialSteps]

. Click *Select files* and upload sample files to analyze. 
+
You can upload up to 10 files with a size limit of 8 MB per file. 
. Click *Run* to analyze the files and get a preview of the results. 

The document action editor shows a preview of the analyzed document that you can zoom in and out for better visibility. Navigate the different pages of the document using the *Previous* (*<*) and *Next* (*>*) buttons. Switching pages updates the extracted values shown in the *Outputs* section. 

include::partial$create-document-actions.adoc[tag=highlightedValues]

After uploading the sample files, configure the schema. 

[[configure-schema]]
== Configure the Schema for the Extraction

Configure the schema by selecting fields to hide from the response, fields that are required, and the minimum confidence score accepted for each field:

. In the *Outputs* section, click *Fields* and select any of the extracted field names to configure the following settings: 
+
--
** *Visibility*: defines if this field shows in the output JSON result. Click *Visibility* (image:visibility-icon.png[2%, 2%, "The Visibility icon"]) to hide this field. 
** *Threshold*: the minimum required confidence score accepted for this field. If the returned *Confidence* value is below the threshold, the document is queued for human review. 
** *Required*: select this option to send the document to review if the field is missing or can't be extracted. 

You can click *Focus* (image:focus-icon.png[2%, 2%, "The Focus icon"]) to center the preview in the corresponding field.
--
. If your document contains tables, click *Tables* to configure the extraction settings for the table columns. 

After configuring the schema, add Prompts to your document action.

[[add-prompts]]
== Add Prompts to Refine the Result

Add Prompts to refine the results of the extraction by asking questions about the document using natural language:

. In the *Outputs* panel, click *Prompts*.
. Click *Add New*.
. Configure the required details: 
** *Name*: a unique name for the query.
** *Instruction*: a question or request in natural language.
+
[WARNING]
Prompts don't support special characters.
+
** *Required*: select this option to send the document to review if the question can't be answered. 
** *Confidence Threshold*: the minimum accepted value to prevent the document from getting queued for review. 
. Click *Add*.
. Click *Run* to analyze the document again and see the results of the prompts.
. Click *Save*. 

== Analyze Documents With Einstein

By default, IDP uses its natural language processing model (IDP NLP) to extract data based on the configured prompts. When you create a document action, you can specify the model that analyzes the document and produces a response for each prompt.

To analyze the document with Einstein: 

. <<add-prompts, Add a new prompt and run a document analysis>>.
. Locate the results in the *Outputs* panel. 
. Click the dropdown button (image:prompt-dropdown.png[4%, 4%, "The prompt dropdown icon."]), next to a prompt's result.
. Select the response labeled *Einstein*.

When you query a published a document action, IDP returns one response per prompt based on the model selected when creating the document action. 

Use Einstein to answer complex questions about the document, such as asking the total of an invoice after deducting taxes and other concepts, or asking in which language the document is written. 

See xref:example-einstein-prompts.adoc[] for additional details. 

== See Also 

* xref:adding-reviewers.adoc[]
* xref:publishing-document-actions.adoc[]
* xref:rpa-home::index.adoc[]
