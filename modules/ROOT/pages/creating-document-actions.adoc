= Creating Document Actions 

include::partial$document-action.adoc[tag=definition] 

Create a document action using a predefined type as a template, and then specify which fields are mandatory, which fields to exclude from the JSON response, and the minimum confidence score expected for each field. 

You can extract additional data from a document using questions in natural language, for example:

* What is the subtotal amount?
* What is the grand total?
* When is the due date?
* What is the highest price?

After you create a new document action, you can add reviewers and publish it to Anypoint Exchange, which enables RPA to execute the document action and also creates an API that you can call from any external system. 

When you create a document action, ensure that the configured schema works for each uploaded document. If you can't customize the schema to work with all sample documents, consider creating multiple document actions. For example, purchase orders from multiple vendors might be different enough to require a separate document action for each vendor.

Creating and customizing a document action requires the following tasks:

. <<create-new-document-action>>
. <<upload-files>>
. <<configure-schema>>
. <<add-prompts>>

== Before You Begin 

Ensure you have any of the following Anypoint permissions:

include::partial$permissions.adoc[tag=permissionManage]

include::partial$permissions.adoc[tag=permissionBuild]

[[create-new-document-action]]
== Create a New Document Action 

To start extracting data from documents, create a new document action: 

//starting steps
include::partial$create-document-actions.adoc[tags=initialSteps;!selectGenericType]

Next, upload samples files to test the extraction. 

//upload sample file
[[upload-files]]
include::partial$create-document-actions.adoc[tag=uploadSampleFileStep]

[[configure-schema]]
== Configure the Schema for the Extraction

Configure the schema by selecting fields to hide from the response, fields that are required, and the minimum confidence score accepted for each field:

. In the *Outputs* section, click *Fields* and select any of the extracted field names to configure the following settings: 
+
--
** *Visibility*: defines if this field shows in the output JSON result. 
+ 
Click *Visibility* (image:visibility-icon.png[2%, 2%, "The Visibility icon"]) to hide this field. 
** *Threshold*: the minimum required confidence score accepted for this field. 
+
If the returned *Confidence* value is below the threshold, the document is queued for human review. 
** *Required*: select this option to send the document to review if the field is missing or can't be extracted. 

You can click *Focus* (image:focus-icon.png[2%, 2%, "The Focus icon"]) to center the preview in the corresponding field.
--
. If your document contains tables, click *Tables* to configure *Visibility*, *Threshold*, and *Required* settings for each of the table columns. 

After configuring the schema, add Prompts to your document action.

[[add-prompts]]
== Add Prompts to Refine the Result

Add Prompts to refine the results of the extraction by asking questions about the document using natural language:

. In the *Outputs* panel, click *Prompts*.
. Click *Add New*.
. Configure the required details: 
** *Name*: a unique name for the query.
** *Instruction*: a question or request in natural language.
+
[WARNING]
Prompts don't support special characters.
+
** *Required*: select this option to send the document to review if the question can't be answered. 
** *Confidence Threshold*: the minimum accepted value to prevent the document from getting queued for review. 
. Click *Add*.
. Click *Run* to analyze the document again and see the results of the prompts.
. Click *Save*. 

////
=== Using Einstein's Response

After you configure prompts and run a document analysis:

* Locate the results in the *Outputs* panel. 
* Click the dropdown button (image:prompt-dropdown.png[4%, 4%, "The prompt dropdown icon."]), next to a prompt's result.
* Select the option labeled *By Einstein*.

Use Einstein to answer complex questions about the document, such as asking the total of an invoice after deducting taxes and other concepts, or asking in which language the document is written. 

See xref:example-einstein-prompts.adoc[] for additional details. 
////

== See Also 

* xref:adding-reviewers.adoc[]
* xref:publishing-document-actions.adoc[]
* xref:rpa-home::index.adoc[]
